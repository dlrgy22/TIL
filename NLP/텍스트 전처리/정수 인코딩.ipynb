{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "supreme-mason",
   "metadata": {},
   "source": [
    "컴퓨터는 텍스트보다 숫자를 더 잘 처리\n",
    "=> 자연어처리에서는 텍스트를 숫자로 바꾸는 여러가지 기법\n",
    "먼저 각 단어를 고유한 정수에 맵핑(mapping)시키는 전처리 작업이 필요\n",
    "\n",
    "**단어에 정수를 부여하는 하나의 방법으로 단어를 빈도수 순으로 정렬한 단어 집합을 만들고 빈도수가 높은 순서대로 차례로 낮은 숫자부터 정수를 부여하는 방법**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "headed-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\"\n",
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "contrary-shaft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
     ]
    }
   ],
   "source": [
    "vocab = defaultdict(int)\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "sentence_list = []\n",
    "for sentence in sentences:\n",
    "    sentence = word_tokenize(sentence)\n",
    "    result = []\n",
    "    for word in sentence:\n",
    "        word = word.lower()\n",
    "        if word not in stop_words and len(word) > 2:\n",
    "            vocab[word] += 1\n",
    "            result.append(word)\n",
    "    sentence_list.append(result)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "beneficial-football",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n"
     ]
    }
   ],
   "source": [
    "vocab_sorted = sorted(vocab.items(), key=lambda x : x[1], reverse = True)\n",
    "print(vocab_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "comparable-terrorist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2idx : {'OOV': 0, 'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n",
      "idx2word : {0: 'OOV', 1: 'barber', 2: 'secret', 3: 'huge', 4: 'kept', 5: 'person', 6: 'word', 7: 'keeping'}\n"
     ]
    }
   ],
   "source": [
    "word2idx = {}\n",
    "idx2word = {}\n",
    "\n",
    "word2idx[\"OOV\"] = 0\n",
    "idx2word[0] =\"OOV\"\n",
    "for idx, (word, freq) in enumerate(vocab_sorted):\n",
    "    if freq < 2:\n",
    "        break\n",
    "    word2idx[word] = idx + 1\n",
    "    idx2word[idx + 1] = word\n",
    "print(f\"word2idx : {word2idx}\")\n",
    "print(f\"idx2word : {idx2word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "beneficial-clarity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 0, 5], [1, 3, 5], [0, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 0, 1, 0], [1, 0, 3, 0]]\n"
     ]
    }
   ],
   "source": [
    "encode = []\n",
    "for sentence in sentence_list:\n",
    "    tmp = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            tmp.append(word2idx[word])\n",
    "        except:\n",
    "            tmp.append(word2idx[\"OOV\"])\n",
    "    encode.append(tmp)\n",
    "print(encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-style",
   "metadata": {},
   "source": [
    "Counter 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "loved-award",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barber' 'person' 'barber' 'good' 'person' 'barber' 'huge' 'person'\n",
      " 'knew' 'secret' 'secret' 'kept' 'huge' 'secret' 'huge' 'secret' 'barber'\n",
      " 'kept' 'word' 'barber' 'kept' 'word' 'barber' 'kept' 'secret' 'keeping'\n",
      " 'keeping' 'huge' 'secret' 'driving' 'barber' 'crazy' 'barber' 'went'\n",
      " 'huge' 'mountain']\n",
      "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "print(sentence_list)\n",
    "sentence_list = np.hstack(sentence_list)\n",
    "# 빈도수로 정렬된 dictionary\n",
    "vocab_Counter = Counter(sentence_list)\n",
    "print(vocab_Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "elder-brown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]\n"
     ]
    }
   ],
   "source": [
    "# NLTK의 FreqDist => Counter같이 사용가능\n",
    "from nltk import FreqDist\n",
    "\n",
    "vocab = FreqDist(sentence_list)\n",
    "print(vocab.most_common(5))\n",
    "\n",
    "word2idx = {word[0] : index + 1 for index, word in enumerate(vocab)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
