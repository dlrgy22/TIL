{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adapted-roberts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082163</th>\n",
       "      <td>20170630</td>\n",
       "      <td>when is it ok to compliment a womans smile a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082164</th>\n",
       "      <td>20170630</td>\n",
       "      <td>white house defends trumps tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082165</th>\n",
       "      <td>20170630</td>\n",
       "      <td>winter closes in on tasmania as snow ice falls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082166</th>\n",
       "      <td>20170630</td>\n",
       "      <td>womens world cup australia wins despite atapat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082167</th>\n",
       "      <td>20170630</td>\n",
       "      <td>youtube stunt death foreshadowed by tweet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1082168 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         publish_date                                      headline_text\n",
       "0            20030219  aba decides against community broadcasting lic...\n",
       "1            20030219     act fire witnesses must be aware of defamation\n",
       "2            20030219     a g calls for infrastructure protection summit\n",
       "3            20030219           air nz staff in aust strike for pay rise\n",
       "4            20030219      air nz strike to affect australian travellers\n",
       "...               ...                                                ...\n",
       "1082163      20170630  when is it ok to compliment a womans smile a g...\n",
       "1082164      20170630                   white house defends trumps tweet\n",
       "1082165      20170630     winter closes in on tasmania as snow ice falls\n",
       "1082166      20170630  womens world cup australia wins despite atapat...\n",
       "1082167      20170630          youtube stunt death foreshadowed by tweet\n",
       "\n",
       "[1082168 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/franciscadias/data/master/abcnews-date-text.csv\", filename=\"abcnews-date-text.csv\")\n",
    "data = pd.read_csv('abcnews-date-text.csv', error_bad_lines=False)\n",
    "print(len(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pediatric-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data[[\"headline_text\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "figured-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "text[\"headline_text\"] = text.apply(lambda row: nltk.word_tokenize(row[\"headline_text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "enormous-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words(\"english\")\n",
    "text[\"headline_text\"] = text[\"headline_text\"].apply(lambda x : [word for word in x if word not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stone-graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       headline_text\n",
      "0   [aba, decides, community, broadcasting, licence]\n",
      "1    [act, fire, witnesses, must, aware, defamation]\n",
      "2     [g, calls, infrastructure, protection, summit]\n",
      "3          [air, nz, staff, aust, strike, pay, rise]\n",
      "4  [air, nz, strike, affect, australian, travellers]\n"
     ]
    }
   ],
   "source": [
    "print(text.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "square-pound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[aba, decide, community, broadcast, licence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[act, fire, witness, must, aware, defamation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[g, call, infrastructure, protection, summit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[air, nz, staff, aust, strike, pay, rise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[air, nz, strike, affect, australian, travellers]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text\n",
       "0       [aba, decide, community, broadcast, licence]\n",
       "1      [act, fire, witness, must, aware, defamation]\n",
       "2      [g, call, infrastructure, protection, summit]\n",
       "3          [air, nz, staff, aust, strike, pay, rise]\n",
       "4  [air, nz, strike, affect, australian, travellers]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "text[\"headline_text\"] = text[\"headline_text\"].apply(lambda x : [WordNetLemmatizer().lemmatize(word, pos=\"v\") for word in x])\n",
    "text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "municipal-freeze",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [decide, community, broadcast, licence]\n",
       "1      [fire, witness, must, aware, defamation]\n",
       "2    [call, infrastructure, protection, summit]\n",
       "3                   [staff, aust, strike, rise]\n",
       "4      [strike, affect, australian, travellers]\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_doc = text[\"headline_text\"].apply(lambda x : [word for word in x if len(word) > 3])\n",
    "tokenize_doc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accurate-advancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           headline_text\n",
      "0     decide community broadcast licence\n",
      "1     fire witness must aware defamation\n",
      "2  call infrastructure protection summit\n",
      "3                 staff aust strike rise\n",
      "4    strike affect australian travellers\n"
     ]
    }
   ],
   "source": [
    "detokenized_doc = []\n",
    "for token in tokenize_doc:\n",
    "    detokenized_doc.append(\" \".join(token))\n",
    "\n",
    "text[\"headline_text\"] = detokenized_doc\n",
    "\n",
    "print(text.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rising-finger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1082168, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features = 1000)\n",
    "X = vectorizer.fit_transform(text[\"headline_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exotic-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# 토픽이 10개\n",
    "lda_model=LatentDirichletAllocation(n_components=10,learning_method='online',random_state=777,max_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cardiac-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_top = lda_model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "original-vault",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 521)\t0.6080934005080666\n",
      "  (0, 191)\t0.503549348860692\n",
      "  (0, 255)\t0.6137267058883044\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "reliable-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('government', 8725.19), ('sydney', 8393.29), ('queensland', 7720.12), ('change', 5874.27), ('home', 5674.38)]\n",
      "Topic 2: [('australia', 13691.08), ('australian', 11088.95), ('melbourne', 7528.43), ('world', 6707.7), ('south', 6677.03)]\n",
      "Topic 3: [('death', 5935.06), ('interview', 5924.98), ('kill', 5851.6), ('jail', 4632.85), ('life', 4275.27)]\n",
      "Topic 4: [('house', 6113.49), ('2016', 5488.19), ('state', 4923.41), ('brisbane', 4857.21), ('tasmania', 4610.97)]\n",
      "Topic 5: [('court', 7542.74), ('attack', 6959.64), ('open', 5663.0), ('face', 5193.63), ('warn', 5115.01)]\n",
      "Topic 6: [('market', 5545.86), ('rural', 5502.89), ('plan', 4828.71), ('indigenous', 4223.4), ('power', 3968.26)]\n",
      "Topic 7: [('charge', 8428.8), ('election', 7561.63), ('adelaide', 6758.36), ('make', 5658.99), ('test', 5062.69)]\n",
      "Topic 8: [('police', 12092.44), ('crash', 5281.14), ('drug', 4290.87), ('beat', 3257.58), ('rise', 2934.92)]\n",
      "Topic 9: [('fund', 4693.03), ('labor', 4047.69), ('national', 4038.68), ('council', 4006.62), ('claim', 3604.75)]\n",
      "Topic 10: [('trump', 11966.41), ('perth', 6456.53), ('report', 5611.33), ('school', 5465.06), ('woman', 5456.76)]\n"
     ]
    }
   ],
   "source": [
    "# 각 토픽에 가장 가까운 단어\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "def get_topics(components, feature_names, n=5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(2)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "get_topics(lda_model.components_,terms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
