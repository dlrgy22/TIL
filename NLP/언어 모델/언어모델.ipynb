{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "geological-liability",
   "metadata": {},
   "source": [
    "언어모델은 언어라는 현상을 모델링하고자 단어 시퀀스에 확률을 할당하는 모델, 이전 단어들이 주어졌을 때 다음 단어를 예측\n",
    "- 통계를 이용한 방법\n",
    "- 인공신경망을 이용한 방법 => 최근 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-metropolitan",
   "metadata": {},
   "source": [
    "P(W)=P(w1,w2,w3,w4,w5,...,wn) : n개의 단어가 들어있는 단어시퀀스 W의 등장 확률\n",
    "P(wn|w1,...,wn−1) : n - 1 개의 단어가 주어졌을 때 그 다음 단어가 등장할 확률\n",
    "앞에 어떤 단어들이 나왔는지 고려하여 후보가 될 수 있는 여러 단어들에 대해서 등장 확률을 추정하고 가장 높은 확률을 가진 단어를 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-jonathan",
   "metadata": {},
   "source": [
    "카운트 기반의 접근\n",
    "다음 단어에 대한 예측 확률 => 전체 데이터에 대하여 통계적으로 확률을 계산\n",
    "=> 카운트 기반 접근은 희소 문제가 발생한다. (충분한 데이터를 관측하지 못하여 언어를 정확히 모델링하지 못하는 문제)\n",
    "\n",
    "=> ngram, 스무딩, 백오프와 같은 여러가지 일반화 기법을 통하여 완화 할 수 있지만 근본적인 해결책은 되지 못한다.\n",
    "=> 통계적 언어 모델에서 인공 신경망 언어 모델로 넘어가게 된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
